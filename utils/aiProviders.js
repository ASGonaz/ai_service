// utils/aiProviders.js
// Queue-based AI provider interface (enqueues jobs, returns results)
import { 
  enqueueAudioTranscription, 
  enqueueImageDescription, 
  enqueueOCR, 
  enqueueTextGeneration 
} from "../queues/queueManager.js";

/**
 * Initialize AI providers (compatibility function)
 */
export function initializeProviders(groqApiKey, geminiApiKey, deepgramApiKey, assemblyAIApiKey) {
  // This function is kept for compatibility but providers are initialized in workers
  if (!groqApiKey && !geminiApiKey && !deepgramApiKey && !assemblyAIApiKey) {
    console.warn("âš ï¸ No AI provider API keys set");
  }
}


/**
 * Transcribe audio using queue system
 * @param {string} audioUrl - URL to audio file
 * @param {Object} options - Options (language, priority, etc.)
 * @returns {Promise<{text: string, language: string|null, provider: string}>}
 */
export async function transcribeAudio(audioUrl, options = {}) {
  console.log("ğŸ¤ Enqueuing audio transcription...");
  
  const job = await enqueueAudioTranscription(audioUrl, options);
  
  // Wait for job to complete
  const result = await job.finished();
  
  console.log("âœ… Audio transcription completed");
  return result;
}


/**
 * Describe image using queue system
 * @param {string} imageUrl - URL to image
 * @param {string} prompt - Description prompt
 * @param {Object} options - Options (priority, etc.)
 * @returns {Promise<{description: string, provider: string}>}
 */
export async function describeImage(imageUrl, prompt = "ØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚ ÙˆØ¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.", options = {}) {
  console.log("ğŸ–¼ï¸ Enqueuing image description...");
  
  const job = await enqueueImageDescription(imageUrl, prompt, options);
  
  // Wait for job to complete
  const result = await job.finished();
  
  console.log("âœ… Image description completed");
  return result;
}

/**
 * Extract text (OCR) from image using queue system - âœ¨ NEW
 * @param {string} imageUrl - URL to image
 * @param {Array<string>} languages - Languages to extract (default: ["ar", "en"])
 * @param {Object} options - Options (priority, etc.)
 * @returns {Promise<{text: string, hasText: boolean, languages: Array, provider: string}>}
 */
export async function extractText(imageUrl, languages = ["ar", "en"], options = {}) {
  console.log("ğŸ“ Enqueuing OCR...");
  
  const job = await enqueueOCR(imageUrl, languages, options);
  
  // Wait for job to complete
  const result = await job.finished();
  
  console.log("âœ… OCR completed");
  return result;
}


/**
 * Generate RAG answer using queue system
 * @param {string} question - User question
 * @param {Array} contexts - Retrieved context documents
 * @param {Object} options - Generation options
 * @returns {Promise<{answer: string, provider: string}>}
 */
export async function generateRAGAnswer(question, contexts, options = {}) {
  const { maxTokens = 500, temperature = 0.7 } = options;

  const contextText = contexts
    .map((ctx, idx) => `${idx + 1}. ${ctx.text}`)
    .join('\n');
console.log("model contextText:", contextText);
  const prompt = `Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© ÙÙ‚Ø·:

${contextText}

Ø§Ù„Ø³Ø¤Ø§Ù„: ${question}
Ø§Ù„Ø¬ÙˆØ§Ø¨:`;

  const systemPrompt = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ. Ø£Ø¬Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¹Ø·Ø§Ø© ÙÙ‚Ø·. ÙƒÙ† Ø¯Ù‚ÙŠÙ‚Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹.";

  console.log("ğŸ¤– Enqueuing RAG generation...");
  
  const job = await enqueueTextGeneration(prompt, systemPrompt, {
    maxTokens,
    temperature,
    ...options
  });
  
  // Wait for job to complete
  const result = await job.finished();
  
  console.log("âœ… RAG answer generated");
  return result;
}

/**
 * Generate text using queue system (direct export for server.js)
 */
export { enqueueTextGeneration };

export { enqueueAudioTranscription, enqueueImageDescription, enqueueOCR };
